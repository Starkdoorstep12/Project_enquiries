{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'CustomerInteractionData.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['LocationID'].fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "median_call_duration = data['CallDurationSeconds'].median()\n",
    "data['CallDurationSeconds'].fillna(median_call_duration, inplace=True)\n",
    "\n",
    "\n",
    "data['AgentID'].fillna('Unknown', inplace=True)\n",
    "data['CustomerID'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "missing_values_after = data.isnull().sum()\n",
    "missing_values_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "file_path = 'CustomerInteractionData.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REGEX = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = REGEX.sub('', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['CustomerInteractionRawText'] = data['CustomerInteractionRawText'].apply(normalize_text)\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(data[['CustomerInteractionRawText']])\n",
    "\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data[['CustomerInteractionRawText']])\n",
    "val_dataset = Dataset.from_pandas(val_data[['CustomerInteractionRawText']])\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['CustomerInteractionRawText'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "dataset_split = tokenized_train_dataset.train_test_split(test_size=0.1)  \n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset_split['train'],\n",
    "    'test': dataset_split['test']\n",
    "})\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset_dict['train'],\n",
    "    eval_dataset=dataset_dict['test'], \n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_results = trainer.evaluate(eval_dataset=tokenized_val_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "while(True):\n",
    "    customer_interaction = input(\"Enter customer interaction: \")\n",
    "    if customer_interaction == \"exit\":\n",
    "        break\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    input_ids = tokenizer.encode(customer_interaction, return_tensors='pt')\n",
    "\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=150,\n",
    "        num_return_sequences=1,\n",
    "        temperature=1,\n",
    "        top_k=50,\n",
    "        do_sample=True,  \n",
    "        top_p=0.95  \n",
    "    )\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Generated Response: \", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "while(True):\n",
    "    \n",
    "    customer_name = input(\"Enter the customer's name: \")\n",
    "    customer_interaction_history = input(\"Enter the customer's interaction history: \")\n",
    "\n",
    "    customer_data = {\n",
    "        \"name\": customer_name,\n",
    "        \"interaction_history\": customer_interaction_history\n",
    "    }\n",
    "    if customer_name == \"exit\":\n",
    "        break\n",
    "\n",
    "    personalized_input = f\"{customer_data['name']} has the following history: {customer_data['interaction_history']}\"\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    input_ids = tokenizer.encode(personalized_input, return_tensors='pt')\n",
    "\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=150,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.9,  \n",
    "        top_k=50,\n",
    "        top_p=0.92,  \n",
    "        do_sample=True,  \n",
    "        early_stopping=True  \n",
    "    )\n",
    "    personalized_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Personalized Response: \", personalized_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

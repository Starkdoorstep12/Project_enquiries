{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RecordID</th>\n",
       "      <th>CustomerInteractionRawText</th>\n",
       "      <th>AgentAssignedTopic</th>\n",
       "      <th>LocationID</th>\n",
       "      <th>CallDurationSeconds</th>\n",
       "      <th>AgentID</th>\n",
       "      <th>CustomerID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1890041</td>\n",
       "      <td>Cus not satisfied with service. want to port o...</td>\n",
       "      <td>Port Out</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>z88Nr</td>\n",
       "      <td>5Ms7y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1890042</td>\n",
       "      <td>Jadav called to check his porting out status. ...</td>\n",
       "      <td>Port Out</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>xGAVI</td>\n",
       "      <td>s8Zyb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1890043</td>\n",
       "      <td>Customer thraetened to cancel her service. Sai...</td>\n",
       "      <td>Port Out</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>T7Kdd</td>\n",
       "      <td>3IB8J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1890044</td>\n",
       "      <td>called to ask steps for porting out. She is le...</td>\n",
       "      <td>Port Out</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>jtifd</td>\n",
       "      <td>mtR3W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1890045</td>\n",
       "      <td>Customer dissatisfied with support. Connectivi...</td>\n",
       "      <td>Port Out</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>hxY3d</td>\n",
       "      <td>DbBmN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RecordID                         CustomerInteractionRawText  \\\n",
       "0   1890041  Cus not satisfied with service. want to port o...   \n",
       "1   1890042  Jadav called to check his porting out status. ...   \n",
       "2   1890043  Customer thraetened to cancel her service. Sai...   \n",
       "3   1890044  called to ask steps for porting out. She is le...   \n",
       "4   1890045  Customer dissatisfied with support. Connectivi...   \n",
       "\n",
       "  AgentAssignedTopic  LocationID  CallDurationSeconds AgentID CustomerID  \n",
       "0           Port Out         8.0                 10.0   z88Nr      5Ms7y  \n",
       "1           Port Out         1.0                  6.0   xGAVI      s8Zyb  \n",
       "2           Port Out         9.0                 15.0   T7Kdd      3IB8J  \n",
       "3           Port Out         5.0                 15.0   jtifd      mtR3W  \n",
       "4           Port Out         7.0                 13.0   hxY3d      DbBmN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'CustomerInteractionData.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_10188\\3526559753.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['LocationID'].fillna(-1, inplace=True)\n",
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_10188\\3526559753.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['CallDurationSeconds'].fillna(median_call_duration, inplace=True)\n",
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_10188\\3526559753.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['AgentID'].fillna('Unknown', inplace=True)\n",
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_10188\\3526559753.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['CustomerID'].fillna('Unknown', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RecordID                      0\n",
       "CustomerInteractionRawText    0\n",
       "AgentAssignedTopic            0\n",
       "LocationID                    0\n",
       "CallDurationSeconds           0\n",
       "AgentID                       0\n",
       "CustomerID                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data['LocationID'].fillna(-1, inplace=True)\n",
    "\n",
    "\n",
    "median_call_duration = data['CallDurationSeconds'].median()\n",
    "data['CallDurationSeconds'].fillna(median_call_duration, inplace=True)\n",
    "\n",
    "\n",
    "data['AgentID'].fillna('Unknown', inplace=True)\n",
    "data['CustomerID'].fillna('Unknown', inplace=True)\n",
    "\n",
    "\n",
    "missing_values_after = data.isnull().sum()\n",
    "missing_values_after\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\OneDrive\\Desktop\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:00<00:00, 2166.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 21/21 [00:00<00:00, 1780.37 examples/s]\n",
      "c:\\Users\\vedan\\OneDrive\\Desktop\\venv\\Lib\\site-packages\\transformers\\training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "                                               \n",
      " 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 19/57 [04:35<06:16,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 7.106177806854248, 'eval_runtime': 10.5092, 'eval_samples_per_second': 0.856, 'eval_steps_per_second': 0.19, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 38/57 [07:53<02:32,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.600682735443115, 'eval_runtime': 8.8853, 'eval_samples_per_second': 1.013, 'eval_steps_per_second': 0.225, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                               \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 57/57 [11:09<00:00, 11.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.4972662925720215, 'eval_runtime': 8.9409, 'eval_samples_per_second': 1.007, 'eval_steps_per_second': 0.224, 'epoch': 3.0}\n",
      "{'train_runtime': 669.0778, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.085, 'train_loss': 6.3596962376644735, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=57, training_loss=6.3596962376644735, metrics={'train_runtime': 669.0778, 'train_samples_per_second': 0.327, 'train_steps_per_second': 0.085, 'total_flos': 57222955008000.0, 'train_loss': 6.3596962376644735, 'epoch': 3.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split  \n",
    "from datasets import Dataset, DatasetDict\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "file_path = 'CustomerInteractionData.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "REGEX = re.compile(r'[^a-zA-Z0-9\\s]')\n",
    "\n",
    "def normalize_text(text):\n",
    "    text = text.lower()\n",
    "    text = REGEX.sub('', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in STOPWORDS]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['CustomerInteractionRawText'] = data['CustomerInteractionRawText'].apply(normalize_text)\n",
    "\n",
    "\n",
    "dataset = Dataset.from_pandas(data[['CustomerInteractionRawText']])\n",
    "\n",
    "\n",
    "train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_data[['CustomerInteractionRawText']])\n",
    "val_dataset = Dataset.from_pandas(val_data[['CustomerInteractionRawText']])\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['CustomerInteractionRawText'], padding='max_length', truncation=True, max_length=512)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "dataset_split = tokenized_train_dataset.train_test_split(test_size=0.1)  \n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset_split['train'],\n",
    "    'test': dataset_split['test']\n",
    "})\n",
    "\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    evaluation_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=dataset_dict['train'],\n",
    "    eval_dataset=dataset_dict['test'], \n",
    ")\n",
    "\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:13<00:00,  4.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 5.759483337402344, 'eval_runtime': 19.6742, 'eval_samples_per_second': 1.067, 'eval_steps_per_second': 0.152, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate(eval_dataset=tokenized_val_dataset)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Response:  pizza.\n",
      "\n",
      "The event will take place in downtown Washington from 6 p.m. to 7 p.m. in the Village Village Apartments. The event will include a wine tasting with local chefs and food enthusiasts. Tickets are $17 for adults and $25 for children under 5.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "while(True):\n",
    "    customer_interaction = input(\"Enter customer interaction: \")\n",
    "    if customer_interaction == \"exit\":\n",
    "        break\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    input_ids = tokenizer.encode(customer_interaction, return_tensors='pt')\n",
    "\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=150,\n",
    "        num_return_sequences=1,\n",
    "        temperature=1,\n",
    "        top_k=50,\n",
    "        do_sample=True,  \n",
    "        top_p=0.95  \n",
    "    )\n",
    "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Generated Response: \", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Personalized Response:  vedant has the following history: sadistic and violent, and has a particular history of being an animal lover.\n",
      "\n",
      "If you find that you are a child or young person who has a history of animal cruelty, please contact us to discuss this with the Animal Welfare Department.\n",
      "\n",
      "Calls to see the animal welfare department are now closed.\n",
      "\n",
      "Please contact us on 0319 723 754\n",
      "\n",
      "Email to: animalwelfare@australia.gov.au.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "while(True):\n",
    "    \n",
    "    customer_name = input(\"Enter the customer's name: \")\n",
    "    customer_interaction_history = input(\"Enter the customer's interaction history: \")\n",
    "\n",
    "    customer_data = {\n",
    "        \"name\": customer_name,\n",
    "        \"interaction_history\": customer_interaction_history\n",
    "    }\n",
    "    if customer_name == \"exit\":\n",
    "        break\n",
    "\n",
    "    personalized_input = f\"{customer_data['name']} has the following history: {customer_data['interaction_history']}\"\n",
    "\n",
    "    tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "    model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "    input_ids = tokenizer.encode(personalized_input, return_tensors='pt')\n",
    "\n",
    "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long, device=input_ids.device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_length=150,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.9,  \n",
    "        top_k=50,\n",
    "        top_p=0.92,  \n",
    "        do_sample=True,  \n",
    "        early_stopping=True  \n",
    "    )\n",
    "    personalized_response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"Personalized Response: \", personalized_response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
